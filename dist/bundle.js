(()=>{"use strict";function e(){return e=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var o in n)({}).hasOwnProperty.call(n,o)&&(e[o]=n[o])}return e},e.apply(null,arguments)}function t(e){const t=new Uint8Array(e);return window.btoa(String.fromCharCode(...t))}function n(e){const t=window.atob(e),n=t.length,o=new Uint8Array(n);for(let e=0;e<n;e++)o[e]=t.charCodeAt(e);return o.buffer}const o=new Blob(['\n      const TARGET_SAMPLE_RATE = 16000;\n      class RawAudioProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = TARGET_SAMPLE_RATE / 4; // Define the threshold for buffer size to be ~0.25s\n\n          if (globalThis.LibSampleRate && sampleRate !== TARGET_SAMPLE_RATE) {\n            globalThis.LibSampleRate.create(1, sampleRate, TARGET_SAMPLE_RATE).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n        }\n        process(inputs, outputs) {\n          const input = inputs[0]; // Get the first input node\n          if (input.length > 0) {\n            let channelData = input[0]; // Get the first channel\'s data\n\n            // Resample the audio if necessary\n            if (this.resampler) {\n              channelData = this.resampler.full(channelData);\n            }\n\n            // Add channel data to the buffer\n            this.buffer.push(...channelData);\n            // Get max volume \n            let sum = 0.0;\n            for (let i = 0; i < channelData.length; i++) {\n              sum += channelData[i] * channelData[i];\n            }\n            const maxVolume = Math.sqrt(sum / channelData.length);\n            // Check if buffer size has reached or exceeded the threshold\n            if (this.buffer.length >= this.bufferSize) {\n              const float32Array = new Float32Array(this.buffer)\n              let pcm16Array = new Int16Array(float32Array.length);\n\n              // Iterate through the Float32Array and convert each sample to PCM16\n              for (let i = 0; i < float32Array.length; i++) {\n                // Clamp the value to the range [-1, 1]\n                let sample = Math.max(-1, Math.min(1, float32Array[i]));\n            \n                // Scale the sample to the range [-32768, 32767] and store it in the Int16Array\n                pcm16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n              }\n            \n              // Send the buffered data to the main script\n              this.port.postMessage([pcm16Array, maxVolume]);\n            \n              // Clear the buffer after sending\n              this.buffer = [];\n            }\n          }\n          return true; // Continue processing\n        }\n      }\n      registerProcessor("raw-audio-processor", RawAudioProcessor);\n  '],{type:"application/javascript"}),s=URL.createObjectURL(o);class a{static async create(e){let t=null,n=null;try{const o=navigator.mediaDevices.getSupportedConstraints().sampleRate;t=new window.AudioContext(o?{sampleRate:e}:{});const i=t.createAnalyser();o||await t.audioWorklet.addModule("https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js"),await t.audioWorklet.addModule(s),n=await navigator.mediaDevices.getUserMedia({audio:{sampleRate:{ideal:e},echoCancellation:{ideal:!0},noiseSuppression:{ideal:!0}}});const r=t.createMediaStreamSource(n),c=new AudioWorkletNode(t,"raw-audio-processor");return r.connect(i),i.connect(c),new a(t,i,c,n)}catch(e){var o,i;throw null==(o=n)||o.getTracks().forEach((e=>e.stop())),null==(i=t)||i.close(),e}}constructor(e,t,n,o){this.context=void 0,this.analyser=void 0,this.worklet=void 0,this.inputStream=void 0,this.context=e,this.analyser=t,this.worklet=n,this.inputStream=o}async close(){this.inputStream.getTracks().forEach((e=>e.stop())),await this.context.close()}}const i=new Blob(['\n      class AudioConcatProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffers = []; // Initialize an empty buffer\n          this.cursor = 0;\n          this.currentBuffer = null;\n          this.wasInterrupted = false;\n          this.finished = false;\n\n          this.port.onmessage = ({ data }) => {\n            switch (data.type) {\n              case "buffer":\n                this.wasInterrupted = false;\n                this.buffers.push(new Int16Array(data.buffer));\n                break;\n              case "interrupt":\n                this.wasInterrupted = true;\n                break;\n              case "clearInterrupted":\n                if (this.wasInterrupted) {\n                  this.wasInterrupted = false;\n                  this.buffers = [];\n                  this.currentBuffer = null;\n                }\n            }\n          };\n        }\n        process(_, outputs) {\n          let finished = false;\n          const output = outputs[0][0];\n          for (let i = 0; i < output.length; i++) {\n            if (!this.currentBuffer) {\n              if (this.buffers.length === 0) {\n                finished = true;\n                break;\n              }\n              this.currentBuffer = this.buffers.shift();\n              this.cursor = 0;\n            }\n\n            output[i] = this.currentBuffer[this.cursor] / 32768;\n            this.cursor++;\n\n            if (this.cursor >= this.currentBuffer.length) {\n              this.currentBuffer = null;\n            }\n          }\n\n          if (this.finished !== finished) {\n            this.finished = finished;\n            this.port.postMessage({ type: "process", finished });\n          }\n\n          return true; // Continue processing\n        }\n      }\n\n      registerProcessor("audio-concat-processor", AudioConcatProcessor);\n    '],{type:"application/javascript"}),r=URL.createObjectURL(i);class c{static async create(e){let t=null;try{t=new AudioContext({sampleRate:e});const n=t.createAnalyser(),o=t.createGain();o.connect(n),n.connect(t.destination),await t.audioWorklet.addModule(r);const s=new AudioWorkletNode(t,"audio-concat-processor");return s.connect(o),new c(t,n,o,s)}catch(e){var n;throw null==(n=t)||n.close(),e}}constructor(e,t,n,o){this.context=void 0,this.analyser=void 0,this.gain=void 0,this.worklet=void 0,this.context=e,this.analyser=t,this.gain=n,this.worklet=o}async close(){await this.context.close()}}function l(e){return!!e.type}class u{static async create(e){let t=null;try{var n;const o=null!=(n=e.origin)?n:"wss://api.elevenlabs.io",s=e.signedUrl?e.signedUrl:o+"/v1/convai/conversation?agent_id="+e.agentId,a=["convai"];e.authorization&&a.push(`bearer.${e.authorization}`),t=new WebSocket(s,a);const i=await new Promise(((n,o)=>{t.addEventListener("open",(()=>{var n;const o={type:"conversation_initiation_client_data"};var s,a,i,r;e.overrides&&(o.conversation_config_override={agent:{prompt:null==(s=e.overrides.agent)?void 0:s.prompt,first_message:null==(a=e.overrides.agent)?void 0:a.firstMessage,language:null==(i=e.overrides.agent)?void 0:i.language},tts:{voice_id:null==(r=e.overrides.tts)?void 0:r.voiceId}}),e.customLlmExtraBody&&(o.custom_llm_extra_body=e.customLlmExtraBody),null==(n=t)||n.send(JSON.stringify(o))}),{once:!0}),t.addEventListener("error",o),t.addEventListener("close",o),t.addEventListener("message",(e=>{const t=JSON.parse(e.data);l(t)&&("conversation_initiation_metadata"===t.type?n(t.conversation_initiation_metadata_event):console.warn("First received message is not conversation metadata."))}),{once:!0})})),r=i.conversation_id,c=parseInt(i.agent_output_audio_format.replace("pcm_",""));return new u(t,r,c)}catch(e){var o;throw null==(o=t)||o.close(),e}}constructor(e,t,n){this.socket=void 0,this.conversationId=void 0,this.sampleRate=void 0,this.socket=e,this.conversationId=t,this.sampleRate=n}close(){this.socket.close()}sendMessage(e){this.socket.send(JSON.stringify(e))}}const d={clientTools:{}},h={onConnect:()=>{},onDebug:()=>{},onDisconnect:()=>{},onError:()=>{},onMessage:()=>{},onModeChange:()=>{},onStatusChange:()=>{}};class p{static async startSession(t){const n=e({},d,h,t);n.onStatusChange({status:"connecting"});let o=null,s=null,i=null;try{return o=await a.create(16e3),s=await u.create(t),i=await c.create(s.sampleRate),new p(n,s,o,i)}catch(e){var r,l,g;throw n.onStatusChange({status:"disconnected"}),null==(r=s)||r.close(),await(null==(l=o)?void 0:l.close()),await(null==(g=i)?void 0:g.close()),e}}constructor(e,o,s,a){var i=this;this.options=void 0,this.connection=void 0,this.input=void 0,this.output=void 0,this.lastInterruptTimestamp=0,this.mode="listening",this.status="connecting",this.inputFrequencyData=void 0,this.outputFrequencyData=void 0,this.volume=1,this.endSession=async function(){"connected"===i.status&&(i.updateStatus("disconnecting"),i.connection.close(),await i.input.close(),await i.output.close(),i.updateStatus("disconnected"))},this.updateMode=e=>{e!==this.mode&&(this.mode=e,this.options.onModeChange({mode:e}))},this.updateStatus=e=>{e!==this.status&&(this.status=e,this.options.onStatusChange({status:e}))},this.onEvent=async function(e){try{const n=JSON.parse(e.data);if(!l(n))return;switch(n.type){case"interruption":n.interruption_event&&(i.lastInterruptTimestamp=n.interruption_event.event_id),i.fadeOutAudio();break;case"agent_response":i.options.onMessage({source:"ai",message:n.agent_response_event.agent_response});break;case"user_transcript":i.options.onMessage({source:"user",message:n.user_transcription_event.user_transcript});break;case"internal_tentative_agent_response":i.options.onDebug({type:"tentative_agent_response",response:n.tentative_agent_response_internal_event.tentative_agent_response});break;case"client_tool_call":if(i.options.clientTools.hasOwnProperty(n.client_tool_call.tool_name)){try{var t;const e=null!=(t=await i.options.clientTools[n.client_tool_call.tool_name](n.client_tool_call.parameters))?t:"Client tool execution successful.";i.connection.sendMessage({type:"client_tool_result",tool_call_id:n.client_tool_call.tool_call_id,result:e,is_error:!1})}catch(e){i.onError("Client tool execution failed with following error: "+(null==e?void 0:e.message),{clientToolName:n.client_tool_call.tool_name}),i.connection.sendMessage({type:"client_tool_result",tool_call_id:n.client_tool_call.tool_call_id,result:"Client tool execution failed: "+(null==e?void 0:e.message),is_error:!0})}break}if(i.options.onUnhandledClientToolCall){i.options.onUnhandledClientToolCall(n.client_tool_call);break}i.onError(`Client tool with name ${n.client_tool_call.tool_name} is not defined on client`,{clientToolName:n.client_tool_call.tool_name}),i.connection.sendMessage({type:"client_tool_result",tool_call_id:n.client_tool_call.tool_call_id,result:`Client tool with name ${n.client_tool_call.tool_name} is not defined on client`,is_error:!0});break;case"audio":i.lastInterruptTimestamp<=n.audio_event.event_id&&(i.addAudioBase64Chunk(n.audio_event.audio_base_64),i.updateMode("speaking"));break;case"ping":i.connection.sendMessage({type:"pong",event_id:n.ping_event.event_id});break;default:i.options.onDebug(n)}}catch(t){return void i.onError("Failed to parse event data",{event:e})}},this.onInputWorkletMessage=e=>{"connected"===this.status&&this.connection.sendMessage({user_audio_chunk:t(e.data[0].buffer)})},this.onOutputWorkletMessage=({data:e})=>{"process"===e.type&&this.updateMode(e.finished?"listening":"speaking")},this.addAudioBase64Chunk=async function(e){i.output.gain.gain.value=i.volume,i.output.worklet.port.postMessage({type:"clearInterrupted"}),i.output.worklet.port.postMessage({type:"buffer",buffer:n(e)})},this.fadeOutAudio=async function(){i.updateMode("listening"),i.output.worklet.port.postMessage({type:"interrupt"}),i.output.gain.gain.exponentialRampToValueAtTime(1e-4,i.output.context.currentTime+2),setTimeout((()=>{i.output.gain.gain.value=i.volume,i.output.worklet.port.postMessage({type:"clearInterrupted"})}),2e3)},this.onError=(e,t)=>{console.error(e,t),this.options.onError(e,t)},this.calculateVolume=e=>{if(0===e.length)return 0;let t=0;for(let n=0;n<e.length;n++)t+=e[n]/255;return t/=e.length,t<0?0:t>1?1:t},this.getId=()=>this.connection.conversationId,this.setVolume=({volume:e})=>{this.volume=e},this.getInputByteFrequencyData=()=>(null!=this.inputFrequencyData||(this.inputFrequencyData=new Uint8Array(this.input.analyser.frequencyBinCount)),this.input.analyser.getByteFrequencyData(this.inputFrequencyData),this.inputFrequencyData),this.getOutputByteFrequencyData=()=>(null!=this.outputFrequencyData||(this.outputFrequencyData=new Uint8Array(this.output.analyser.frequencyBinCount)),this.output.analyser.getByteFrequencyData(this.outputFrequencyData),this.outputFrequencyData),this.getInputVolume=()=>this.calculateVolume(this.getInputByteFrequencyData()),this.getOutputVolume=()=>this.calculateVolume(this.getOutputByteFrequencyData()),this.options=e,this.connection=o,this.input=s,this.output=a,this.options.onConnect({conversationId:o.conversationId}),this.connection.socket.addEventListener("message",(e=>{this.onEvent(e)})),this.connection.socket.addEventListener("error",(e=>{this.updateStatus("disconnected"),this.onError("Socket error",e)})),this.connection.socket.addEventListener("close",(()=>{this.updateStatus("disconnected"),this.options.onDisconnect()})),this.input.worklet.port.onmessage=this.onInputWorkletMessage,this.output.worklet.port.onmessage=this.onOutputWorkletMessage,this.updateStatus("connected")}}let g=null,f=null;function m(e){const t=document.getElementById("connectionStatus");t.textContent=e?"Conectado":"Desconectado",t.classList.toggle("connected",e)}function v(e){const t=document.getElementById("speakingStatus"),n=document.querySelector(".pulse-blur"),o="speaking"===e.mode;t.textContent=o?"Agent Speaking":"Agent Silent",t.classList.toggle("speaking",o),n.style.display=o?"block":"none",console.log("Speaking status updated:",{mode:e,isSpeaking:o})}document.getElementById("startButton").addEventListener("click",(async function(){const e=document.getElementById("startButton"),t=document.getElementById("endButton");if(f)try{if(!await async function(){try{return await navigator.mediaDevices.getUserMedia({audio:!0}),!0}catch(e){return console.error("Microphone permission denied:",e),!1}}())return void alert("Microphone permission is required for the conversation.");g=await p.startSession({signedUrl:f,onConnect:()=>{console.log("Connected"),m(!0),e.disabled=!0,t.disabled=!1},onDisconnect:()=>{console.log("Disconnected"),m(!1),e.disabled=!1,t.disabled=!0,v({mode:"listening"})},onError:e=>{console.error("Conversation error:",e),alert("An error occurred during the conversation.")},onModeChange:e=>{console.log("Mode changed:",e),v(e)}})}catch(e){console.error("Error starting conversation:",e),alert("Failed to start conversation. Please try again.")}else alert("Signed URL do assistente não carregado ainda.")})),document.getElementById("endButton").addEventListener("click",(async function(){g&&(await g.endSession(),g=null)})),window.addEventListener("error",(function(e){console.error("Global error:",e.error)})),window.addEventListener("DOMContentLoaded",(async()=>{const e=window.location.pathname.split("/").filter(Boolean).pop()||"";if(e)try{const t=await fetch(`/api/assistente/${e}`);if(!t.ok)throw new Error("Não foi possível carregar os dados do assistente.");const n=await t.json();document.getElementById("nome").innerText=n.nome,document.getElementById("descricao").innerText=n.descricao,document.getElementById("avatar").src=n.foto_url,document.body.style.backgroundImage=`url('${n.background_image}')`,f=n.signed_url}catch(e){console.error("Erro ao carregar assistente:",e),document.getElementById("nome").innerText="Erro ao carregar assistente."}else console.warn("Nenhum slug encontrado na URL, não iniciando requisição.")}))})();